{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-DNMwHoqo9W"
   },
   "source": [
    "In this notebook, we'll test out feature engineering for the photometric redshift problem, and take a look at the feature importance. \n",
    "\n",
    "Copyright: Viviana Acquaviva (2023); see also other data credits below.\n",
    "\n",
    "Modifications by Julieta Gruszko (2025)\n",
    "\n",
    "License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)\n",
    "\n",
    "The problem is inspired by [this paper](https://arxiv.org/abs/1903.08174), for which the data are public and available [here](http://d-scholarship.pitt.edu/36064/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-wwIPLaqo9Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "\n",
    "font = {'size'   : 16}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "#matplotlib.rcParams.update({'figure.autolayout': True})\n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost # install xgboost if you don't have it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_z7DV-Yqo9b"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szeIiCf9qo9b"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqS3CaJAq72x"
   },
   "source": [
    "We read in the selection of data as in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ly0GfOtaqo9c"
   },
   "outputs": [],
   "source": [
    "sel_features = pd.read_csv('../Data/sel_features.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzT9b_W8qo9d"
   },
   "outputs": [],
   "source": [
    "sel_target = pd.read_csv('../Data/sel_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JodoYMvfqo9d",
    "outputId": "4d152bd1-cb61-411f-ce40-b11721917c4e"
   },
   "outputs": [],
   "source": [
    "sel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8skafA4fqo9e",
    "outputId": "e7da0ebc-9853-4a4f-8e81-6a26e418ce4c"
   },
   "outputs": [],
   "source": [
    "sel_target.values.ravel() #changes shape to 1d row-like array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wi-MVgQDqo9f"
   },
   "source": [
    "### I'll demonstrate how to check the feature importance using Random Forests as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbsrxafIqo9g"
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(max_features=4, n_estimators=200) #I need to re-seed the random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxoCFf7sqo9h"
   },
   "source": [
    "After the model has been fit, it will have the attribute \"feature\\_importances\\_\". These are calculated based on the decrease of impurity method. We can look at the feature importance using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OycMfXOUqo9i",
    "outputId": "7a28ea2f-fdd0-4be1-99eb-ab26e7d4a6da",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(sel_features, sel_target.values.ravel()) \n",
    "\n",
    "#note: this is not doing any train/test split, but fitting the entire data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d06jNlmqo9j",
    "outputId": "0348651d-ca70-477b-f07c-0bf34934f9ad"
   },
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFjylv-Dqo9j"
   },
   "source": [
    "The code below plots the feature importances. You'll need to adapt it to show the results for multiple models, so you can compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44Mtqm9yqo9j",
    "outputId": "4dec4cc1-4b73-4131-cdf4-7f6bfad8132d"
   },
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(sel_features.shape[1]):\n",
    "    print(\"%d. feature: %s, %d (%f)\" % (f + 1, sel_features.columns[indices[f]], indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(sel_features.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(sel_features.shape[1]), sel_features.columns[indices])\n",
    "plt.xlim([-1, sel_features.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Feature Engineering\n",
    "In the paper that we used as a reference (https://arxiv.org/abs/1903.08174), the authors actually use colors, not magnitudes, as features (or to be precise: one magnitude and five colors). Find in the paper the exact list of features (hint: it's in Section 7), and generate the new features to match what is done there. Note: a color is the ratio of brightness in two bands, but because the brightness in each band is expressed in magnitudes, which is a logarithmic unit (i.e. it's proportional to log(luminosity)), you can obtain colors by subtracting two bands.\n",
    "\n",
    "Then, compare the performance of an $\\textbf{optimized}$ Random Forest model using 3 options for features:\n",
    "- Version 1: 6 magnitudes, as demonstrated in Studio 8. No need to repeat the work from studio, you can just cite the result you found.\n",
    "- Version 2: 1 magnitude and 5 colors, as described in the paper.\n",
    "- Version 3: Include all the features from Version 1 and Version 2, yielding 6 magnitudes and 5 colors as your full set of features. \n",
    "\n",
    "Compare the outlier fraction and $\\sigma_{NMAD}$ for the 3 versions, taking into account the uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Feature Importance\n",
    "\n",
    "Using the features from Version 3 in Step 1, calculate the feature importance for each of the 11 features. In a plot, compare the feature importances found using RandomForest, AdaBoost, and XGBoost methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PHYS448",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
