{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95c57b7",
   "metadata": {},
   "source": [
    "### Studio 13: Our First CNN\n",
    "\n",
    "Original Author: Andrew Connolly, University of Washington Thanks to Hayden Smotherman, University of Washington for the example networks.\n",
    "\n",
    "This notebook is based on work by Javier Duarte for UCSD PHYS 139/239: Machine Learning in Physics (2023), https://jduarte.physics.ucsd.edu/phys139_239\n",
    "\n",
    "Modifications by Julieta Gruszko (2025).\n",
    "\n",
    "In this notebook we work through a simple example for a neural network and CNN using Keras. Initially we will start with a fully connected neural network, and then study a simple a convolutional neural network. Then we'll see how we can start to understand what the network is doing. \n",
    "\n",
    "The data we are using is taken from a survey for NEOs by Lori Allen and collaborators using DECam on the Blanco 4m Telescope at CTIO. The data comprise a stack of images taken over a period of 5 nights. Within these images we search for slowly moving sources (TNOs) along potential orbital trajectories. Given these trajectories we coadd the images. Our goal is to determine whether there is a point source within the coadded images. The training sample includes images of simulated TNOs (true positives; stamps_sources.npz) and random trajectories where there is no known source (false positives; stamps_noise.npz). The true positives range in signal-to-noise from 100 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ca3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch as torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764b78c",
   "metadata": {},
   "source": [
    "Here are some helper functions we'll use for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a139bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "\n",
    "def normalize_image(image):\n",
    "    '''Rescale the constrast in an image based on the noise (used for displays and the CNN)'''\n",
    "    sigmaG_coeff =  0.7413\n",
    "    image = image.reshape(21,21)\n",
    "    \n",
    "    per25,per50,per75 = np.percentile(image,[25,50,75])\n",
    "    sigmaG = sigmaG_coeff * (per75 - per25)\n",
    "    # sigma clip image, remove background, and normalize to unity\n",
    "    image[image<(per50-2*sigmaG)] = per50-2*sigmaG\n",
    "    image -= np.min(image)\n",
    "    image /= np.sum(image)\n",
    "    \n",
    "    return image\n",
    "    \n",
    "def plot_image_array(images, nrows=2, ncols=5, figsize=[8,4], nx=21, ny=21, title='', subtitle=False, \n",
    "                     class_true=None, classes=None):\n",
    "    '''Plot an array of images'''\n",
    "    fig, ax = plt.subplots(nrows=nrows,ncols=ncols,figsize=figsize)\n",
    "    fig.subplots_adjust(hspace=.3, left=0.07, right=0.95, wspace=0.1, bottom=0.15)\n",
    "    for indx in np.arange(nrows*ncols):\n",
    "        i = int(indx/ncols)\n",
    "        j = indx%ncols\n",
    "        if (i == 0):\n",
    "            ax[i][j].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        if (j != 0):\n",
    "            ax[i][j].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "        ax[i][j].imshow(images[indx].reshape(nx,ny), cmap='gray')\n",
    "        if (subtitle == True):\n",
    "            ax[i][j].set_title('True Class: %d, Pred Class: %d\\n  Prob Class 1 %.1f ' % \n",
    "              (np.argmax(class_true[indx]), np.argmax(classes[indx]), classes[indx,1]), color='blue', fontsize=6)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    ax[0][0].set_ylabel('$y$')\n",
    "    ax[nrows-1][int(ncols/2)].set_xlabel('$x$')            \n",
    "    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, \n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues, \n",
    "                          ylabel = 'True label', \n",
    "                          xlabel = 'Predicted label'):\n",
    "    \"\"\"\n",
    "    From scikit-learn: plots a confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           title=title,\n",
    "           ylabel=ylabel,\n",
    "           xlabel=xlabel)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    #fixes \"squishing of plot\"\n",
    "    plt.ylim([1.5, -.5]) \n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "def plot_model_history(history, n_epochs):\n",
    "    '''Plot the training and validation history for a TensorFlow network'''\n",
    "\n",
    "    # Extract loss and accuracy\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1,ncols=2, figsize=(10,5))\n",
    "    ax[0].plot(np.arange(n_epochs), loss, label='Training Loss')\n",
    "    ax[0].plot(np.arange(n_epochs), val_loss, label='Validation Loss')\n",
    "    ax[0].set_title('Loss Curves')\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "\n",
    "    ax[1].plot(np.arange(n_epochs), acc, label='Training Accuracy')\n",
    "    ax[1].plot(np.arange(n_epochs), val_acc, label='Validation Accuracy')\n",
    "    ax[1].set_title('Accuracy Curves')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ff07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = np.load(\"../Data/stamps_sources.npy\")\n",
    "noise = np.load(\"../Data/stamps_noise.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea97d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2fa92",
   "metadata": {},
   "source": [
    "Our data is in the form of numpy arrays, which contain the true positive source and false positive noise images. Each image is 21x21 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab66eb5",
   "metadata": {},
   "source": [
    "### Question: \n",
    "How many source instances do we have? How many noise instances? Is our data set balanced or unbalanced?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450d52f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9d51213",
   "metadata": {},
   "source": [
    "As we learned last week, we need to normalize the data! In this case, we don't want to normalize each pixel separately (that would destroy the image information we want our CNN to learn), but we do want every image to have the same range of brightness values and contrast. We'll use the helper function given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing images\n",
    "\n",
    "point_source_stamps = []\n",
    "for image in sources:\n",
    "    point_source_stamps.append(normalize_image(image))\n",
    "\n",
    "no_point_source_stamps = []\n",
    "for image in noise:\n",
    "    no_point_source_stamps.append(normalize_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c787b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sample of images\n",
    "plot_image_array(no_point_source_stamps, title='false positives')\n",
    "plot_image_array(point_source_stamps, title='true positives')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ccf6d",
   "metadata": {},
   "source": [
    "We don't actually have labels stored yet, since our labels come from which file each instance is associated with. The first thing we'll do is combine the instances from both files and make appropriate labels (0 for noise, 1 for a true point source).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36978712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the false positives and true positives\n",
    "input_stamps = np.vstack([no_point_source_stamps, point_source_stamps])\n",
    "stamp_class = np.zeros(len(no_point_source_stamps) + len(point_source_stamps))\n",
    "stamp_class[len(no_point_source_stamps) :] = 1  # 0 for noise, 1 for a star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e9d7bd",
   "metadata": {},
   "source": [
    "We'll need one more helper function, to reshape the feature data and turn our labels into 1-hot encoded arrays. \n",
    "\n",
    "Pytorch has a $\\texttt{one\\_hot}$ method that makes this easy, we just need to get our numpy array into a tensor first. The way it works, the first column is used for the \"noise\" category encoding, and the second column is used for the \"signal\" category encoding. \n",
    "\n",
    "So [1, 0] will indicate that the category label for the instance was \"0\" (it was a noise instance) and [0, 1] will indicate that the category label was \"1\" (it was a true point source).\n",
    "\n",
    "We could also have used sk-learn's one-hot encoder, but that one requires some extra lines of code, so I went with the pytorch version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ff4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to reshape array into what keras expects\n",
    "def reshape_arrays(data, labels):\n",
    "    \"\"\"reshape arrays for Keras\"\"\"\n",
    "    data = data.reshape(-1, 21, 21, 1)\n",
    "    labels = nn.functional.one_hot(torch.from_numpy(labels).long())\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6e1667",
   "metadata": {},
   "source": [
    "We will use sk-learn's $\\texttt{train\\_test\\_split}$ to split the data in to random selections with appropriate fractions of sources. We'll split twice to make training, validation, and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the samples into training, validation and, test data sets:\n",
    "train_frac = 0.7\n",
    "val_frac = 0.1\n",
    "test_frac = 0.2\n",
    "# Note: we have to use train_test_split twice\n",
    "data_train_val, data_test, class_train_val, class_test = train_test_split(\n",
    "    input_stamps, stamp_class, test_size=test_frac, random_state=42\n",
    ")\n",
    "data_train, data_val, class_train, class_val = train_test_split(\n",
    "    input_stamps, stamp_class, test_size=val_frac / (train_frac + val_frac), random_state=42\n",
    ")\n",
    "\n",
    "data_train, class_train = reshape_arrays(data_train, class_train)\n",
    "data_val, class_val = reshape_arrays(data_val, class_val)\n",
    "data_test, class_test = reshape_arrays(data_test, class_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Number of samples in the training ({}); test ({}); and validation ({}) data sets'.format(data_train.shape[0], \n",
    "                                                                                    data_test.shape[0],\n",
    "                                                                                   data_val.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2d7aa",
   "metadata": {},
   "source": [
    "For the sake of comparison, we'll study 2 models: a fully-connected neural network like the ones we tried last week, and a CNN model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eed59b6",
   "metadata": {},
   "source": [
    "### Version 1: Fully-Connected Neural Network\n",
    "\n",
    "First, we'll try a fully-connected neural network using an input layer and a hidden layer. \n",
    "\n",
    "Along the way, I'll show you how to output labels for multiple categories (instead of probabilities of belonging to the positive category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras import Input\n",
    "\n",
    "from keras.models import Sequential #the model is built adding layers one after the other\n",
    "\n",
    "from keras.layers import Dense #fully connected layers: every output talks to every input\n",
    "\n",
    "from keras.layers import Flatten #for flattening tensor data\n",
    "\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e8782",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fc = Sequential()\n",
    "\n",
    "# Tell subsequent layers what shape to expect\n",
    "model_fc.add(keras.Input(shape=(21, 21, 1)))\n",
    "\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=0.001)\n",
    "\n",
    "# Add an input layer and specify its size (number of original features)\n",
    "\n",
    "model_fc.add(Dense(30, activation='relu', input_shape=(21, 21, 1)))\n",
    "\n",
    "# Add one hidden layer and specify its size\n",
    "\n",
    "model_fc.add(Dense(30, activation='relu'))\n",
    "\n",
    "# output layer \n",
    "\n",
    "model_fc.add(Flatten()) # because our inputs have been in the form of 2D tensors, we need to flatten them here\n",
    "\n",
    "model_fc.add(Dense(2, activation='softmax')) #instead of outputting just 1 value (probability of positive category), we'll output 2 values that correspond to our 1-hot encoding scheme\n",
    "\n",
    "model_fc.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #we'll use cross-entropy loss to optimize, and monitor the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_fc.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea11dc",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- How many hidden layers does the network have? \n",
    "- How many free parameters does the network have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3edc5c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a633213",
   "metadata": {},
   "source": [
    "We begin with 20 epochs and batch size = 300. This took about 3 minutes on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6333463",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = model_fc.fit(data_train, class_train, validation_data= (data_val, class_val), epochs=20, batch_size=300, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dcc620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pred = model_fc.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d9bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22393d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "# Feel free to turn normalization off to see the number of instances in each category instead\n",
    "plot_confusion_matrix(np.argmax(class_test,axis=1), np.argmax(class_pred,axis=1), normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8775dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history of the network\n",
    "plot_model_history(mynet, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855921ca",
   "metadata": {},
   "source": [
    "### Questions about the fully-connected network:\n",
    "- Does the network appear to have converged in the number of epochs we used? Should we use more training epochs?\n",
    "- Does this network have a problem with high variance? High bias?\n",
    "- Give the test accuracy of the fully connected network (you'll probably need to do a little math using the confusion matrix above!).\n",
    "- Are the recall and precision of the network balanced, or is the network giving more of one type of error (false positive vs. false negative)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6e35c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1485f50e",
   "metadata": {},
   "source": [
    "### Version 2: CNN\n",
    "\n",
    "Now let's try a relatively simple CNN!\n",
    "\n",
    "We'll try a model with 3 convolution layers and 2 max pooling layers.\n",
    "At the end, we still want a fully connected layer to connect information from different parts of the image, plus our fully connected output layer that actually performs the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9879bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ba9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.AdamW(learning_rate=0.001)\n",
    "\n",
    "model = Sequential()\n",
    "# input: 21x21 images with 1 channel -> (21, 21, 1) tensors.\n",
    "# this applies 16 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(21, 21, 1), name='conv1'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', name='conv2'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', name='conv3'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu', name='fc_1'))\n",
    "# output layer\n",
    "\n",
    "model.add(Dense(2, activation='softmax', name='fc_out'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #we'll use cross-entropy loss to optimize, and monitor the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ec3fd",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- How many hidden layers does the network have? Layers that don't add weights, like drop-out or pooling layers, are not considered hidden layers: they're \"packaged\" with the hidden layer they modify.\n",
    "- How many free parameters does the network have?\n",
    "- How do the number of free parameters in this model compare to the number in the fully connected neural network above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b24dafa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ae59873",
   "metadata": {},
   "source": [
    "Now we'll train the model, using 20 epochs again. To speed things up a bit, I'll use a batch size of 1000. \n",
    "This took about 2 minutes on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c23fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycnn = model.fit(data_train, class_train, validation_data= (data_val, class_val), epochs=20, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pred_cnn = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56be22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(np.argmax(class_test,axis=1), np.argmax(class_pred_cnn,axis=1), normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b665d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history of the network\n",
    "plot_model_history(mycnn, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90af2a2",
   "metadata": {},
   "source": [
    "### Questions about the CNN:\n",
    "- Does the network appear to have converged in the number of epochs we used? Should we use more training epochs?\n",
    "- Does this network have a problem with high variance? High bias?\n",
    "- Give the test accuracy of the CNN (you'll probably need to do a little math using the confusion matrix above!).\n",
    "- Are the recall and precision of the network balanced, or is the network giving more of one type of error (false positive vs. false negative)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d743b01",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d13d5f9c",
   "metadata": {},
   "source": [
    "### Question:\n",
    "- Which seems to perform better, the fully connected neural network, or the convolutional neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d1d4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1178cf7",
   "metadata": {},
   "source": [
    "### Understanding Neural Network Results\n",
    "\n",
    "\n",
    "An interesting question to ask might be: what types of events is our network having trouble with? And are they the same ones the fully connected network had trouble with? Let's look at the images.\n",
    "\n",
    "One issue we need to work with is that the predicted labels don't have values 0 or 1, they have decimal labels. We need to round the predicted labels first.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pred_fc_rounded = np.round(class_pred)\n",
    "class_pred_cnn_rounded = np.round(class_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select images where the CNN labels don't match the true labels\n",
    "# This isn't a very numpy-y way to do this, but it's easy to understand what's happening\n",
    "test_mismatch_cnn = []\n",
    "test_mismatch_cnn_true_labels = []\n",
    "test_mismatch_cnn_pred_labels = []\n",
    "\n",
    "for i in range(data_test.shape[0]):\n",
    "    if np.all(class_pred_cnn_rounded[i] != class_test[i].numpy()):\n",
    "        test_mismatch_cnn.append(data_test[i])\n",
    "        test_mismatch_cnn_true_labels.append(class_test[i].numpy())\n",
    "        test_mismatch_cnn_pred_labels.append(class_pred_cnn[i])\n",
    "\n",
    "test_mismatch_cnn = np.array(test_mismatch_cnn)\n",
    "test_mismatch_cnn_true_labels = np.array(test_mismatch_cnn_true_labels)\n",
    "test_mismatch_cnn_pred_labels = np.array(test_mismatch_cnn_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for the fully connected network\n",
    "\n",
    "test_mismatch_fc = []\n",
    "test_mismatch_fc_true_labels = []\n",
    "test_mismatch_fc_pred_labels = []\n",
    "for i in range(data_test.shape[0]):\n",
    "    if np.all(class_pred_fc_rounded[i] != class_test[i].numpy()):\n",
    "        test_mismatch_fc.append(data_test[i])\n",
    "        test_mismatch_fc_true_labels.append(class_test[i].numpy())\n",
    "        test_mismatch_fc_pred_labels.append(class_pred[i])\n",
    "\n",
    "test_mismatch_fc = np.array(test_mismatch_fc)\n",
    "test_mismatch_fc_true_labels = np.array(test_mismatch_fc_true_labels)\n",
    "test_mismatch_fc_pred_labels = np.array(test_mismatch_fc_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_array(test_mismatch_cnn, title='Mis-classified by CNN', subtitle=True, class_true=test_mismatch_cnn_true_labels, classes=test_mismatch_cnn_pred_labels)\n",
    "plot_image_array(test_mismatch_fc, title = 'Mis-classified by Fully-Connected Neural Network', subtitle=True, class_true=test_mismatch_fc_true_labels, classes=test_mismatch_fc_pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb72d0",
   "metadata": {},
   "source": [
    "### Question:\n",
    "What do you observe about the classification probabilities associated with mis-classified images, in most cases? Is the network confident about these classifications?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861c100",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8450b16",
   "metadata": {},
   "source": [
    "How confident are these networks in general? We can check by making a histogram of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(class_pred[:, 1], bins = 100, color='red', alpha = 0.5, label = \"Fully Connected Predictions\")\n",
    "plt.hist(class_pred_cnn[:, 1], bins = 100, alpha = 0.5, label = \"CNN Predictions\")\n",
    "plt.xlabel(\"Prob of Positive Class\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.legend()\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ab396",
   "metadata": {},
   "source": [
    "### Question:\n",
    "Which network is producing more ambiguous predictions (i.e. more predictions in the middling probability range)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674cd01",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca494eec",
   "metadata": {},
   "source": [
    "From the predictions, it seems like our networks are pretty certain about most of the classifications! An interesting question to ask is whether the networks are every certain and incorrect, or if most of the mis-classifications are happening when the network is uncertain. The first one of these is far more dangerous!\n",
    "\n",
    "Let's set a tighter threshold for classification and see what happens in the CNN. I'll use just the most confident ones: a 0.01 threshold for the negative class, and the 0.99 threshold for the positive class. Feel free to adjust these thresholds and see how things change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true = data_test[class_pred_cnn[:, 1]> 0.5] \n",
    "confident_true = data_test[class_pred_cnn[:, 1]> 0.99]\n",
    "\n",
    "print(f\"The CNN is confident about {confident_true.shape[0]/all_true.shape[0]:.3f} of class 1 predictions.\")\n",
    "\n",
    "all_false = data_test[class_pred_cnn[:, 1]< 0.5] \n",
    "confident_false = data_test[class_pred_cnn[:, 1]< 0.01]\n",
    "\n",
    "print(f\"The CNN is confident about {confident_false.shape[0]/all_false.shape[0]:.3f} of class 0 predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ef9f1",
   "metadata": {},
   "source": [
    "We'll try making a confusion matrix just for the confidently classified instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca8c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_confident = class_test[(class_pred_cnn[:, 1]< 0.01) | (class_pred_cnn[:, 1]> 0.99)]\n",
    "y_pred_confident = class_pred_cnn[(class_pred_cnn[:, 1]< 0.01) | (class_pred_cnn[:, 1]> 0.99)]\n",
    "\n",
    "plot_confusion_matrix(np.argmax(y_true_confident,axis=1), np.argmax(y_pred_confident,axis=1), normalize=False,\n",
    "                      title='Confusion matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dbcbd5",
   "metadata": {},
   "source": [
    "Better! Our false positive rate at this high threshold, in particular, is extremely low. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae983dce",
   "metadata": {},
   "source": [
    "### Interpreting Networks\n",
    "Occulsion maps, saliency maps, class activation maps are all techniques for expressing which pixels contribute to classification. These are attempts to reduce the “black box” nature of the networks. \n",
    "\n",
    "The simplest of these is the occlussion map where we part of an image and calculate the probability of it belonging to a class. If the probability decreases the occluded part of the image is assumed to be important. If there is no change in probability the occluded pixels are not assumed to be important. A simple implementation of this is shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e54569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlusiontest(model, image_number, kernel_size=5):\n",
    "    input_stamp = data_test[image_number].reshape(21,21)\n",
    "    i = 0\n",
    "    j=0\n",
    "    heatmap = []\n",
    "    keras_stamps = []\n",
    "    for j in range(22-kernel_size): # slide the occlusion kernel over the image\n",
    "        for i in range(22-kernel_size):\n",
    "            img = np.copy(input_stamp)\n",
    "            img[i:i+kernel_size,j:j+kernel_size] = 0 # Turn off a section of the image\n",
    "            img = normalize_image(img)\n",
    "            keras_stamps.append(img) # add the occluded image to a list \n",
    "    keras_stamps = np.array(keras_stamps).reshape([-1,21,21,1])\n",
    "    probs = 1. - model.predict(keras_stamps)  # predict for every occluded image\n",
    "    heatmap = probs[:,1].reshape(22-kernel_size,22-kernel_size) # make a heatmap of the probability of correct point source ID given each occluded version\n",
    "    # pad heatmap to same size as original image\n",
    "    heatmap = np.pad(heatmap, pad_width=int(kernel_size/2), mode='minimum')\n",
    "    return heatmap \n",
    "\n",
    "def transparent_cmap(cmap, N=255):\n",
    "    \"Copy colormap and set alpha values\"\n",
    "    mycmap = cmap\n",
    "    mycmap._init()\n",
    "    mycmap._lut[:,-1] = np.linspace(0, 0.8, N+4)\n",
    "    return mycmap\n",
    "\n",
    "def plot_occlusion_array(image_arr, heatmap_arr, nrows=2, ncols=5, figsize=[8,4], nx=21, ny=21, title='', subtitle=False, \n",
    "                     class_true=None, classes=None):\n",
    "\n",
    "\n",
    "    '''Plot an array of images'''\n",
    "    fig, ax = plt.subplots(nrows=nrows,ncols=ncols,figsize=figsize)\n",
    "    fig.subplots_adjust(hspace=.3, left=0.07, right=0.95, wspace=0.1, bottom=0.15)\n",
    "    for indx in np.arange(nrows*ncols):\n",
    "        i = int(indx/ncols)\n",
    "        j = indx%ncols\n",
    "        if (i == 0):\n",
    "            ax[i][j].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        if (j != 0):\n",
    "            ax[i][j].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "        ax[i][j].imshow(image_arr[indx].reshape(nx,ny), cmap='gray')\n",
    "        ax[i][j].imshow(np.array(heatmap_arr[indx]), alpha=0.5, cmap=mycmap)\n",
    "        if (subtitle == True):\n",
    "            ax[i][j].set_title('True Class: %d, Pred Class: %d\\n  Prob Class 1 %.1f ' % \n",
    "              (np.argmax(class_true[indx]), np.argmax(classes[indx]), classes[indx,1]), color='blue', fontsize=6)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    ax[0][0].set_ylabel('$y$')\n",
    "    ax[nrows-1][int(ncols/2)].set_xlabel('$x$')           \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7addb382",
   "metadata": {},
   "source": [
    "Using this code, we can check the importance of each region of an image in making the classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use make a red transparent overlay\n",
    "mycmap = transparent_cmap(plt.cm.Reds)\n",
    "\n",
    "image_number = 1\n",
    "kernel_size = 6\n",
    "heatmap = occlusiontest(model, image_number, kernel_size)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1,ncols=1)\n",
    "ax.imshow(data_test[image_number].reshape(21,21), cmap='gray')\n",
    "ax.imshow(np.array(heatmap), alpha=0.5, cmap=mycmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4cd933",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numbers = np.arange(10) #just looking at the first 10 images here, but you could choose to look at the confidently mis-classified images, for example!\n",
    "heatmap_arr = []\n",
    "image_arr = []\n",
    "for indx in image_numbers:\n",
    "    heatmap_arr.append(occlusiontest(model, indx))\n",
    "    image_arr.append(data_test[indx])\n",
    "\n",
    "heatmap_arr = np.array(heatmap_arr)\n",
    "image_arr = np.array(image_arr)\n",
    "\n",
    "plot_occlusion_array(image_arr, heatmap_arr, subtitle=True, class_true=class_test, classes=class_pred_cnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af660c2f",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- Is the network looking in the same place for all images? \n",
    "- Which parts of the image are most important for images with point sources present? What about for noisy images?\n",
    "- Does the information from the occlusion tests match your expectation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84b7f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3c9b7d7",
   "metadata": {},
   "source": [
    "### Acknowledgement Statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a5a6a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55148675",
   "metadata": {},
   "source": [
    "That's it for today! Go ahead and submit to Gradescope. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PHYS448_DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
